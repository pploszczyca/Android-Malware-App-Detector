import logging

import pandas as pd
from sklearn.preprocessing import LabelEncoder


class DataPreprocessorBuilder:
    def __init__(self, data_name='general', result_col_name='Result'):
        self.data = None
        self.logger = logging.getLogger(__name__)
        self.data_name = data_name
        self.result_col_name = result_col_name

    def load_data(self, file_path: str) -> 'DataPreprocessorBuilder':
        if not file_path.endswith('.csv'):
            raise ValueError("Only CSV files are supported.")

        if self.data is not None:
            self.__log_info("Data has already been loaded. It will be replaced.")

        self.data = pd.read_csv(file_path)
        self.data.drop_duplicates(inplace=True)
        self.__log_info("Data loaded successfully.")
        return self

    def set_data(self, data: pd.DataFrame) -> 'DataPreprocessorBuilder':
        if self.data is not None:
            self.__log_info("Data has already been loaded. It will be replaced.")

        self.data = data
        self.__log_info("Data set successfully.")
        return self

    def show_basic_statistics(self, should_show: bool = False) -> 'DataPreprocessorBuilder':
        if not should_show:
            return self

        self.__require_data()

        self.__log_info("Basic statistics of the data:")

        self.__log_info(f"Data shape: {self.data.shape}")
        self.__log_info("Columns:")
        for column in self.data.columns:
            self.__log_info(f"{column}: {self.data[column].dtype}")

        self.__log_info("Data description:")
        for stat in self.data:
            self.__log_info(f"{stat}: {self.data[stat].describe()}")

        return self

    def add_sum_of_permitted_permissions(self) -> 'DataPreprocessorBuilder':
        self.__require_data()

        self.data['SUM_OF_PERMITTED_PERMISSIONS'] = self.data.drop(self.result_col_name, axis=1).sum(axis=1)
        self.__log_info("Sum of permitted permissions has been added to the data.")

        return self

    def add_sum_of_columns(self, columns: list[str], new_column_name: str) -> 'DataPreprocessorBuilder':
        self.__require_data()

        self.data[new_column_name] = self.data[columns].sum(axis=1)
        self.__log_info(f"Sum of columns {columns} has been added to the data as '{new_column_name}'.")

        return self

    def normalize_label(self) -> 'DataPreprocessorBuilder':
        self.__require_data()

        le = LabelEncoder()
        self.data[self.result_col_name] = le.fit_transform(self.data[self.result_col_name])
        self.__log_info(f"Label column '{self.result_col_name}' has been normalized.")

        for i, label in enumerate(le.classes_):
            self.__log_info(f"Label '{label}' has been encoded as {i}.")

        return self

    def normalize_data(self) -> 'DataPreprocessorBuilder':
        self.__require_data()

        self.data = (self.data - self.data.min()) / (self.data.max() - self.data.min())
        self.__log_info("Data has been normalized.")

        return self

    def remove_unbalanced_columns(self, threshold=0.9) -> 'DataPreprocessorBuilder':
        self.__require_data()

        initial_column_count = self.data.shape[1]
        self.data = self.data.loc[:, (self.data.apply(
            lambda x: x.value_counts(normalize=True).iloc[0] if not x.empty else 1) < threshold)]
        removed_column_count = initial_column_count - self.data.shape[1]

        self.__log_info(f"Unbalanced columns have been removed. {removed_column_count} columns were removed.")

        return self

    def cut_names_from_all_columns(self) -> 'DataPreprocessorBuilder':
        self.__require_data()

        for col in self.data.columns:
            if '.' in col:
                self.data[col.split('.')[-1]] = self.data[col]
                self.data.drop(col, axis=1, inplace=True)
        self.__log_info("Names have been cut from labels in all columns.")

        return self

    def filter_columns(self, columns: list[str]) -> 'DataPreprocessorBuilder':
        self.__require_data()

        for column in columns:
            if column not in self.data.columns:
                raise ValueError(f"Column '{column}' does not exist in the data.")

        self.data = self.data[columns]
        self.__log_info("Columns have been filtered.")

        return self

    def remove_columns_containing_arrow(self) -> 'DataPreprocessorBuilder':
        self.__require_data()

        for column in self.data.columns:
            if '->' in column:
                self.data.drop(column, axis=1, inplace=True)
        self.__log_info("Columns containing '->' have been removed.")

        return self

    def __require_data(self):
        if self.data is None:
            raise ValueError("Data has not been loaded yet.")

    def __log_info(self, message: str):
        self.logger.info(message, extra={'data_name': self.data_name})

    def build(self) -> pd.DataFrame:
        self.__require_data()
        return self.data
