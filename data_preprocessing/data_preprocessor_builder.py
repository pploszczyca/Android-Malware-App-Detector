import logging
from typing import Optional

import pandas as pd
from sklearn.preprocessing import LabelEncoder


class DataPreprocessorBuilder:
    def __init__(self, data_name='general', result_col_name='Result'):
        self.data = None
        logging.basicConfig(level=logging.INFO,
                            format='%(asctime)s - %(name)s - %(levelname)s - %(data_name)s - %(message)s')
        self.logger = logging.getLogger(__name__)
        self.data_name = data_name
        self.result_col_name = result_col_name

    def load_data(self, file_path: str) -> 'DataPreprocessorBuilder':
        self.data = pd.read_csv(file_path)
        self.__log_info("Data loaded successfully.")
        return self

    def show_basic_statistics(self) -> 'DataPreprocessorBuilder':
        self.__require_data()

        self.__log_info("Basic statistics of the data:")

        self.__log_info(f"Data shape: {self.data.shape}")
        self.__log_info("Columns:")
        for column in self.data.columns:
            self.__log_info(f"{column}: {self.data[column].dtype}")

        self.__log_info("Data description:")
        for stat in self.data:
            self.__log_info(f"{stat}: {self.data[stat].describe()}")

        return self

    def add_sum_of_permitted_permissions(self) -> 'DataPreprocessorBuilder':
        self.__require_data()

        self.data['SUM_OF_PERMITTED_PERMISSIONS'] = self.data.drop(self.result_col_name, axis=1).sum(axis=1)
        self.__log_info("Sum of permitted permissions has been added to the data.")

        return self

    def normalize_label(self) -> 'DataPreprocessorBuilder':
        self.__require_data()

        le = LabelEncoder()
        self.data[self.result_col_name] = le.fit_transform(self.data[self.result_col_name])
        self.__log_info(f"Label column '{self.result_col_name}' has been normalized.")

        return self

    def normalize_data(self) -> 'DataPreprocessorBuilder':
        self.__require_data()

        self.data = (self.data - self.data.min()) / (self.data.max() - self.data.min())
        self.__log_info("Data has been normalized.")

        return self

    def remove_unbalanced_columns(self, threshold=0.9) -> 'DataPreprocessorBuilder':
        self.__require_data()

        initial_column_count = self.data.shape[1]
        self.data = self.data.loc[:, (self.data.apply(lambda x: x.value_counts(normalize=True).iloc[0] if not x.empty else 1) < threshold)]
        removed_column_count = initial_column_count - self.data.shape[1]

        self.__log_info(f"Unbalanced columns have been removed. {removed_column_count} columns were removed.")

        return self

    def cut_names_from_all_columns(self) -> 'DataPreprocessorBuilder':
        self.__require_data()

        for col in self.data.columns:
            if '.' in col:
                self.data[col.split('.')[-1]] = self.data[col]
                self.data.drop(col, axis=1, inplace=True)
        self.__log_info("Names have been cut from labels in all columns.")

        return self

    def filter_columns(self, columns: list[str]) -> 'DataPreprocessorBuilder':
        self.__require_data()

        for column in columns:
            if column not in self.data.columns:
                raise ValueError(f"Column '{column}' does not exist in the data.")

        self.data = self.data[columns]
        self.__log_info("Columns have been filtered.")

        return self

    def __require_data(self):
        if self.data is None:
            raise ValueError("Data has not been loaded yet.")

    def __log_info(self, message: str):
        self.logger.info(message, extra={'data_name': self.data_name})

    def build(self, folder_path: Optional[str] = None) -> pd.DataFrame:
        self.__require_data()

        if folder_path is not None:
            self.data.to_csv(folder_path + '/processed_data.csv', index=False)
            self.__log_info("Data saved successfully.")

        return self.data
