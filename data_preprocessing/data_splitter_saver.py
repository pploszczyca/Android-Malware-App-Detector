import logging

import pandas as pd
from sklearn.model_selection import train_test_split
import os

from data_preprocessing.utils import show_basic_data_statistics


class DataSplitterSaver:
    def __init__(self, data_list: list[pd.DataFrame], test_size=0.2, random_state=42):
        self.data = pd.concat(data_list)
        self.test_size = test_size
        self.random_state = random_state
        self.logger = logging.getLogger(__name__)

    def process_and_save(self, folder_path: str, should_show_statistics: bool = False):
        self.__remove_duplicates()
        if should_show_statistics:
            show_basic_data_statistics(self.data, self.logger)
        train_data, test_data = self.__split_data()
        self.__save_data(train_data, test_data, folder_path)

    def __remove_duplicates(self):
        shape = self.data.shape
        self.data.drop_duplicates(inplace=True)
        self.__log_info(f"{shape[0] - self.data.shape[0]} duplicates have been removed.")

    def __split_data(self):
        train_data, test_data = train_test_split(self.data, test_size=self.test_size, random_state=self.random_state)

        return train_data, test_data

    @staticmethod
    def __save_data(train_data, test_data, folder_path):
        if not os.path.exists(folder_path):
            os.makedirs(folder_path)

        train_data.to_csv(os.path.join(folder_path, 'train.csv'), index=False)
        test_data.to_csv(os.path.join(folder_path, 'test.csv'), index=False)

    def __log_info(self, message: str):
        self.logger.info(message, extra={'data_name': "Concatenated Data"})
