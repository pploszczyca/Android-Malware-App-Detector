from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import GradientBoostingClassifier
from training_models.classifier import Classifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC


class NaiveBayesClassifier(Classifier):
    def __init__(self, training_data, test_data):
        super().__init__(training_data, test_data, "Naive Bayes Classifier")
        self.model = GaussianNB()


class DecisionTreeClassifierModel(Classifier):
    def __init__(self, training_data, test_data):
        super().__init__(training_data, test_data, "Decision Tree Classifier")
        dtc = DecisionTreeClassifier()
        self.param_grid = {
            'criterion': ['gini', 'entropy'],
            'max_depth': [None, 10, 20, 30, 40, 50],
            'min_samples_split': [2, 5, 10],
            'min_samples_leaf': [1, 2, 4]
        }
        self.grid_search = GridSearchCV(dtc, self.param_grid, cv=5, scoring='accuracy', verbose=1)


class KNeighborsClassifierModel(Classifier):
    def __init__(self, training_data, test_data):
        super().__init__(training_data, test_data, "K Neighbors Classifier")
        knc = KNeighborsClassifier()

        self.param_grid = {
            'n_neighbors': [3, 5, 8, 10, 15],
            'weights': ['uniform', 'distance'],
            'metric': ['euclidean', 'manhattan', 'minkowski']
        }
        self.grid_search = GridSearchCV(knc, self.param_grid, cv=5, scoring='accuracy')


class LogisticRegressionClassifierModel(Classifier):
    def __init__(self, training_data, test_data):
        super().__init__(training_data, test_data, "Logistic Regression Classifier")
        lr = LogisticRegression(solver='liblinear')
        self.param_grid = {
            'C': [0.01, 0.1, 1, 10, 100],
            'penalty': ['l1', 'l2'],
            'solver': ['liblinear']  # 'liblinear' works well for small datasets and with l1 penalty
        }
        self.grid_search = GridSearchCV(lr, self.param_grid, cv=5, scoring='accuracy')


class RandomForestClassifierModel(Classifier):
    def __init__(self, training_data, test_data):
        super().__init__(training_data, test_data, "Random Forest Classifier")
        rf = RandomForestClassifier(random_state=42)
        param_grid = {
            'n_estimators': [100, 200, 300],
            'max_depth': [10, 20, 30],
            'min_samples_split': [2, 5, 10]
        }
        self.grid_search = GridSearchCV(
            estimator=rf,
            param_grid=param_grid,
            cv=5,
            scoring='accuracy',
        )


class SVMClassifierModel(Classifier):
    def __init__(self, training_data, test_data):
        super().__init__(training_data, test_data, "SVM Classifier")
        svc = SVC(kernel='rbf', C=1.0)
        self.param_grid = {
            'C': [0.1, 1, 10],
            'kernel': ['linear', 'poly', 'rbf'],
            'gamma': ['scale', 'auto']
        }
        self.grid_search = GridSearchCV(svc, self.param_grid, cv=5, scoring='accuracy')


class GBMClassifierModel(Classifier):
    def __init__(self, training_data, test_data):
        super().__init__(training_data, test_data, "Gradient Boosting Classifier")
        gbc = GradientBoostingClassifier()
        self.param_grid = {
            'n_estimators': [100, 200, 300],  # Number of boosting stages to perform
            'learning_rate': [0.01, 0.1, 0.2],  # Shrinks the contribution of each tree
            'max_depth': [3, 5, 8],  # Maximum depth of the individual regression estimators
            'min_samples_split': [2, 5],  # The minimum number of samples required to split an internal node
            'min_samples_leaf': [1, 3],  # The minimum number of samples required to be at a leaf node
            'subsample': [0.9, 1.0],  # The fraction of samples to be used for fitting the individual base learners
            'max_features': ['sqrt', 'log2', None]  # The number of features to consider when looking for the best split
        }
        self.grid_search = GridSearchCV(gbc, self.param_grid, cv=5, scoring='accuracy', verbose=1)
