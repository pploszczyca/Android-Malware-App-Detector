from training_models.classifier import ModelStatistics

from typing import List
import matplotlib.pyplot as plt
import seaborn as sns


def plot_model_statistics(statistics: list[ModelStatistics]):
    for plot in [plot_model_accuracies, plot_prediction_times, plot_classification_metrics, plot_confusion_matrices]:
        plot(statistics)


def plot_model_accuracies(statistics_list: List[ModelStatistics]):
    # Extract model names and accuracies from the list of ModelStatistics objects
    model_names = [stat.name.replace('Classifier', '').strip() for stat in statistics_list]
    accuracies = [stat.accuracy for stat in statistics_list]

    # Create a bar plot
    plt.figure(figsize=(10, 6))
    bars = plt.bar(model_names, accuracies, color='skyblue')

    # Add title and labels
    plt.title('Model Accuracies')
    plt.xlabel('Model')
    plt.ylabel('Accuracy')

    # Add accuracy values on top of the bars
    for bar in bars:
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width() / 2, height, f'{height:.4f}', ha='center', va='bottom')

    # Rotate x-axis labels for better readability
    plt.xticks(rotation=45, ha='right')

    # Adjust y-axis limits to better show differences
    plt.ylim(min(accuracies) - 0.05, max(accuracies) + 0.05)

    # Show plot
    plt.tight_layout()
    plt.show()


def plot_prediction_times(statistics_list: List[ModelStatistics]):
    def create_bar_plot(data, labels, title, color):
        plt.figure(figsize=(10, 6))
        bars = plt.bar(labels, data, color=color)
        plt.title(title)
        plt.xlabel('Model')
        plt.ylabel('Time (seconds)')
        for bar, value in zip(bars, data):
            plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{value:.6f}', ha='center', va='bottom')
        plt.xticks(rotation=45, ha='right')
        plt.tight_layout()
        plt.show()

    model_names = [stat.name.replace('Classifier', '').strip() for stat in statistics_list]
    times_10 = [stat.prediction_time[0.1] for stat in statistics_list]
    times_50 = [stat.prediction_time[0.5] for stat in statistics_list]
    times_100 = [stat.prediction_time[1.0] for stat in statistics_list]

    # Plot for 10% data
    create_bar_plot(times_10, model_names, 'Prediction Time for 10% of Data', 'skyblue')

    # Plot for 50% data
    create_bar_plot(times_50, model_names, 'Prediction Time for 50% of Data', 'lightgreen')

    # Plot for 100% data
    create_bar_plot(times_100, model_names, 'Prediction Time for 100% of Data', 'salmon')


def plot_classification_metrics(statistics_list: List[ModelStatistics]):
    metrics = ['precision', 'recall', 'f1-score', 'support']
    for metric in metrics:
        plt.figure(figsize=(12, 8))
        all_values = []
        for stat in statistics_list:
            data = [stat.classification_report[label][metric] for label in stat.classification_report if
                    isinstance(stat.classification_report[label], dict)]
            labels = [f"{stat.name.replace('Classifier', '').strip()} {label}" for label in stat.classification_report
                      if
                      isinstance(stat.classification_report[label], dict)]
            plt.bar(labels, data, label=f"{stat.name.replace('Classifier', '').strip()}")
            all_values.extend(data)

        plt.title(f'{metric.capitalize()} of Models')
        plt.xlabel('Class')
        plt.ylabel(metric.capitalize())
        plt.legend()
        plt.xticks(rotation=45, ha='right')

        # Adjust y-axis limits to better show differences
        if metric != 'support':
            plt.ylim(min(all_values) - 0.05, max(all_values) + 0.05)
        else:
            plt.ylim(min(all_values) - 100, max(all_values) + 100)

        plt.tight_layout()
        plt.show()


def plot_confusion_matrices(statistics_list: List[ModelStatistics]):
    for stat in statistics_list:
        plt.figure(figsize=(8, 6))
        sns.heatmap(stat.confusion_matrix, annot=True, fmt='d', cmap='Blues')
        plt.title(f'Confusion Matrix for {stat.name.replace("Classifier", "").strip()}')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.show()
